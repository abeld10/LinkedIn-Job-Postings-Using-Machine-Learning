{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Imports\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder = '../archive/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### @author selfadri\n",
    "### Load the datasets into pandas dataframes from csv\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "datasets = {}\n",
    "for dirname, _, filenames in os.walk(input_folder):\n",
    "    for filename in filenames:\n",
    "        if filename.split('.')[-1] != 'csv':\n",
    "            continue\n",
    "        datasets['_'.join((dirname.split('postings')[-1].replace('/',''),filename.split('.')[-2])).strip(input_folder).lstrip('_')] = pd.read_csv(os.path.join(dirname, filename))\n",
    "\n",
    "pprint([*datasets.keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### @author selfadri\n",
    "\n",
    "# Calculate labels, which indicate salary, from any available min-med-max values\n",
    "untrimmed_y = np.mean(datasets['job_postings'].iloc[:,4:7], axis=1)\n",
    "\n",
    "# Clean dataset to remove unwanted samples\n",
    "cond = untrimmed_y.notna() & (datasets['job_postings']['pay_period'] != \"ONCE\")\n",
    "y = untrimmed_y[cond]\n",
    "X = datasets['job_postings'][cond]\n",
    "\n",
    "# Adjust for the `pay_period`\n",
    "assert np.all(np.unique(X.iloc[:,7]) == ['HOURLY', 'MONTHLY', 'WEEKLY', 'YEARLY'])\n",
    "y[X['pay_period'] == \"YEARLY\"] *= 1\n",
    "y[X['pay_period'] == \"MONTHLY\"] *= 12\n",
    "y[X['pay_period'] == \"WEEKLY\"] *= 50\n",
    "y[X['pay_period'] == \"HOURLY\"] *= 40 * 50\n",
    "\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Some samples do not have the salary data needed for our labels.\n",
    "print(f'{(untrimmed_y.size - y.size) / untrimmed_y.size * 100 :.2f} % of samples are lost due to not having salary :)')\n",
    "print(f'{y.size} samples remain.')\n",
    "print('Unfortunately, this is normal for LinkedIn.')\n",
    "print('Maybe we could make a binary classifier for whether or not the employer would post the salary :)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### @author selfadri\n",
    "\n",
    "# Just USD\n",
    "print(np.unique(datasets['job_details_salaries']['currency']))\n",
    "\n",
    "# Not here, nothing new to learn from the job_details_salaries csv\n",
    "print(datasets['job_details_salaries'][datasets['job_details_salaries']['job_id'] == datasets['job_postings'].iloc[2]['job_id']])\n",
    "\n",
    "# Here's the benefit types recorded\n",
    "pprint([*np.unique(np.asarray(datasets['job_details_benefits']['type'], str))])\n",
    "\n",
    "# Here's the work types\n",
    "pprint([*np.unique(X['work_type'])])\n",
    "\n",
    "# Here's the titles\n",
    "print(pd.DataFrame(np.unique(X['title'])))\n",
    "pprint(str(Counter(X['title']))[:1000])\n",
    "\n",
    "# Here's the locations\n",
    "pprint(str(Counter(X['location']))[:1000])\n",
    "\n",
    "# Only a few job postings have skill description paragraphs\n",
    "print(y.size - Counter(np.array(X['skills_desc'] ,str))['nan'])\n",
    "\n",
    "# There are a handful of job types, plenty of each category\n",
    "print(Counter(datasets['job_details_job_skills'].iloc[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### @author selfadri\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features\n",
    "We will consider 10 features for now.\n",
    "- Experience Level\n",
    "- Job Title (Later, embed this)\n",
    "- Work Type (full time, part time, intern, etc.)\n",
    "- Location\n",
    "- Skills\n",
    "- Job Industry\n",
    "- Company Industry\n",
    "- Company Employee Count\n",
    "- Benefits\n",
    "- Company LinkedIn Follower Count\n",
    "- Remote Work Allowed\n",
    "\n",
    "### Scope\n",
    "The location is always in the United States, and the currency is always measured in USD.\n",
    "\n",
    "### Labels (Salary)\n",
    "We extracted our labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# One hot encode the categorical data\n",
    "enc = OneHotEncoder(sparse_output=False)\n",
    "enc.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc.transform(X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(enc.transform(X), y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr = svm.SVR()\n",
    "svr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
