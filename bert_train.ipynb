{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    BertModel, \n",
    "    AutoConfig, \n",
    "    AutoTokenizer, \n",
    "    Trainer,\n",
    "    TrainingArguments\n",
    "    )\n",
    "import torch.nn as nn\n",
    "import datasets\n",
    "import csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_name = \"bert-base-uncased\"\n",
    "config = AutoConfig.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "bert_model = BertModel.from_pretrained(model_name)\n",
    "\n",
    "config.problem_type = 'regression'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Add linear layer\n",
    "output_size = 1  \n",
    "\n",
    "\n",
    "# Combine BERT and the linear layer\n",
    "class BertWithLinear(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BertWithLinear, self).__init__()\n",
    "        self.bert = bert_model.to('cuda')\n",
    "        self.ft = nn.Sequential(\n",
    "            nn.Linear(config.hidden_size, 512),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 16),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, output_size)\n",
    "\n",
    "\n",
    "        ).to('cuda')\n",
    "        \n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None, token_type_ids=None, position_ids=None, head_mask=None, inputs_embeds=None, labels=None):\n",
    "        output = self.bert(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids, position_ids=position_ids, head_mask=head_mask, inputs_embeds=inputs_embeds)\n",
    "        # Use pooled output for classification/regression\n",
    "        pooled_output = output.pooler_output\n",
    "        return self.ft(pooled_output)\n",
    "\n",
    "model = BertWithLinear().to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeze BERT pretrained weights\n",
    "# for param in model.bert.embeddings.parameters():\n",
    "#     param.requires_grad = False\n",
    "model = nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "feats_fp = open(\"BERT_X.csv\", \"r\")\n",
    "labels_fp = open(\"BERT_y.csv\", \"r\")\n",
    "feats = csv.reader(feats_fp)\n",
    "labels = csv.reader(labels_fp)\n",
    "\n",
    "# skip header\n",
    "next(feats)\n",
    "next(labels)\n",
    "\n",
    "unscaled_data = {'text': [], 'label': []}\n",
    "for row in feats:\n",
    "    unscaled_data['text'].append(row[0].strip().replace(\"\\n\", \" \"))\n",
    "for row in labels:\n",
    "    unscaled_data['label'].append(float(row[0].strip().replace(\"\\n\", \"\")))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.58786439, -0.94649659,  2.86819603, ..., -1.04441134,\n",
       "       -0.86218111, -0.69471581])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaled_labels = scaler.fit_transform(np.array(data['label']).reshape(-1,1)).flatten()\n",
    "scaled_data = unscaled_data\n",
    "scaled_data['label'] = scaled_labels\n",
    "scaled_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26990 26990\n"
     ]
    }
   ],
   "source": [
    "print(len(scaled_data['text']), len(scaled_data['label']))\n",
    "assert len(scaled_data['text']) == len(scaled_data['label'])\n",
    "dataset = datasets.Dataset.from_dict(scaled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overview  HearingLife is a national hearing care company and part of the Demant Group, a global leader in hearing healthcare built on a heritage of care, health, and innovation since 1904. HearingLife operates more than 600 hearing care centers across 42 states. We follow a scientific, results-oriented approach to hearing healthcare that is provided by highly skilled and caring professionals. Our vision is to help more people hear better through life-changing hearing health delivered by the best personalized care. This Team Member must uphold the HearingLife Core Values:   We create trust  We are team players  We apply a can-do attitude  We create innovative solutions   Responsibilities  You will help more people hear better by providing clinical expertise to diagnose and treat hearing loss while ensuring a positive patient experience. The Hearing Care Provider acts in accordance with required industry and state professional licensing standards and local practice scope and is responsible for growing and maintaining the practice. This includes achieving all financial goals as well as offering best in class modern hearing healthcare assessment and treatment. The Hearing Care Provider is responsible for creating an exceptional patient journey through patient care and appropriate treatment options.   Provide quality care and aftercare of dispensing services such as hearing tests, hearing aid fittings, educate and train hearing aid users of best practices.  Perform checks on hearing aids and other amplification devices including but not limited to troubleshooting, conducting repairs to hearing aids, earmolds and cleaning of hearing aids.  Achieves growth with a strong mindset on sales and key business metrics while focusing on providing quality patient care.  Continuously develop a relationship with local community leaders by representing HearingLife as an advocate to making a life changing difference.  Ensure clinic inventory meets a sustainable level to drive business including accurate recordkeeping of inventory.  Support Telehealth initiatives (Remote Care) to expand patient care and product portfolio including but not limited conducting hearing tests, coach and educate patients on hearing aid devices.   Qualifications   Maintain an active Hearing Aid Dispensing License in accordance with state requirements.  A minimum of two years of professional experience; previous experience in selling hearing aids in an Audiology/dispensing practice. In lieu of two years of experience, demonstrated previous experience or training or equivalent combination of education and experience.  Maintain continuing education requirements based on state requirements.  Ability to operate audiometric equipment and to interpret the results.  Exceptional critical thinking skills to analyze patient‚Äôs situation.  Excellent interpersonal skills to engage and motivate patients and third parties.  Skill in handling sensitive matters and patients with tact, courtesy, and discretion.  Demonstrated ability to manage multiple tasks efficiently, including determining priorities, organizing work, and working independently in a fast-paced environment.  Ability to communicate test results and interpret and propose treatment in a manner easily understood by patients.   üå¥ Unwind with Paid Time Off: We value work-life balance. Enjoy company-paid holidays, floating holidays, and more!  üíº Flexible Work Dynamics: Experience the future of work with numerous hybrid and remote opportunities tailored for the modern professional.  üåü Comprehensive Health Benefits: Choose from a diverse range of health insurance plans covering medical, dental, vision, and HSA. Your well-being is our priority.  üí∞ Invest in Your Future: With our competitive 401(k) Program, your future looks bright.  üéÅ Exclusive Discounts & Programs: Get special discounts on our products, including hearing aids, for both family and possibly friends. Plus, take advantage of our Employee and Family Purchase Hearing Aid program.  üöÄ Boundless Growth Opportunities   DMIT Program: Dive deep into management insights.  Apprentice Program: Learn from the best in the field.  Amplify Leadership Program: Get one-on-one guidance and real-world exposure to grow and excel as a Leader.   ‚ù§Ô∏è A Thriving, Positive Environment: We live our C ore V alues : We C reate T rust, W e are T eam P layers, W e A pply a C an- D o A ttitude and We C reate I nnovative S olutions.  üìö Empower Your Ambitions: Avail up to $5250 annually with our Education Expense Reimbursement. Keep learning, keep growing!  ü§ù Refer & Earn: Know someone perfect for the team? Our Team Member Referral Program rewards you with up to $3500 per hire, depending on the role.  üõ°Ô∏è Protection for the Unexpected: Enjoy peace of mind with our basic life and AD&D insurance, as well as short-term disability insurance.  Come be part of a team where every day brings new challenges, learning, and the opportunity to make a difference. Join us!  We are an Equal Opportunity / Affirmative Action employer, all qualified applicants will receive consideration for employment  without regard to race, color, religion, sexual orientation, sex, national origin, disability, or protected veteran status.  #HearingLife_US\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[63000.]])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(dataset[0]['text'])\n",
    "scaler.inverse_transform(np.array([dataset[0]['label']]).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "285000.0 22000.0\n"
     ]
    }
   ],
   "source": [
    "# max salary\n",
    "\n",
    "max_salary = max(data['label'])\n",
    "min_salary = min(data['label'])\n",
    "print(max_salary, min_salary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a73e2033584c4313aa5ba77e9d5f3655",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tokenize the dataset\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "def preprocess(examples):\n",
    "    return tokenizer(examples['text'], truncation=True, padding=True)\n",
    "\n",
    "tokenized_dataset = dataset.map(preprocess, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',          \n",
    "    num_train_epochs=3,              \n",
    "    per_device_train_batch_size=16,  \n",
    "    learning_rate=5e-5,               \n",
    "    warmup_steps=500,                \n",
    "    weight_decay=0.01,              \n",
    "    logging_dir='./logs',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set  don't have a corresponding argument in `BertWithLinear.forward` and have been ignored: text. If text are not expected by `BertWithLinear.forward`,  you can safely ignore this message.\n",
      "***** Running training *****\n",
      "  Num examples = 26990\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 633\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Caught RuntimeError in replica 0 on device 0.\nOriginal Traceback (most recent call last):\n  File \"/mnt/home/bhatta70/.local/lib/python3.6/site-packages/torch/nn/parallel/parallel_apply.py\", line 61, in _worker\n    output = module(*input, **kwargs)\n  File \"/mnt/home/bhatta70/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n    result = self.forward(*input, **kwargs)\n  File \"<ipython-input-26-96aa96028594>\", line 27, in forward\n    output = self.bert(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids, position_ids=position_ids, head_mask=head_mask, inputs_embeds=inputs_embeds)\n  File \"/mnt/home/bhatta70/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n    result = self.forward(*input, **kwargs)\n  File \"/opt/software/Python/3.6.4-foss-2018a/lib/python3.6/site-packages/transformers/models/bert/modeling_bert.py\", line 1006, in forward\n    return_dict=return_dict,\n  File \"/mnt/home/bhatta70/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n    result = self.forward(*input, **kwargs)\n  File \"/opt/software/Python/3.6.4-foss-2018a/lib/python3.6/site-packages/transformers/models/bert/modeling_bert.py\", line 592, in forward\n    output_attentions,\n  File \"/mnt/home/bhatta70/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n    result = self.forward(*input, **kwargs)\n  File \"/opt/software/Python/3.6.4-foss-2018a/lib/python3.6/site-packages/transformers/models/bert/modeling_bert.py\", line 477, in forward\n    past_key_value=self_attn_past_key_value,\n  File \"/mnt/home/bhatta70/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n    result = self.forward(*input, **kwargs)\n  File \"/opt/software/Python/3.6.4-foss-2018a/lib/python3.6/site-packages/transformers/models/bert/modeling_bert.py\", line 409, in forward\n    output_attentions,\n  File \"/mnt/home/bhatta70/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n    result = self.forward(*input, **kwargs)\n  File \"/opt/software/Python/3.6.4-foss-2018a/lib/python3.6/site-packages/transformers/models/bert/modeling_bert.py\", line 306, in forward\n    attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\nRuntimeError: CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 11.17 GiB total capacity; 10.52 GiB already allocated; 190.88 MiB free; 10.56 GiB reserved in total by PyTorch)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-7c09bf4fc476>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0meval_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenized_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m )\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/software/Python/3.6.4-foss-2018a/lib/python3.6/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1420\u001b[0m                         \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1421\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1422\u001b[0;31m                     \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1424\u001b[0m                 if (\n",
      "\u001b[0;32m/opt/software/Python/3.6.4-foss-2018a/lib/python3.6/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2010\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautocast_smart_context_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2011\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2013\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_gpu\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/software/Python/3.6.4-foss-2018a/lib/python3.6/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   2041\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2042\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2043\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2044\u001b[0m         \u001b[0;31m# Save past state if it exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2045\u001b[0m         \u001b[0;31m# TODO: this needs to be fixed and made cleaner later.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0mreplicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/parallel/parallel_apply.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m             \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    426\u001b[0m             \u001b[0;31m# have message field\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Caught RuntimeError in replica 0 on device 0.\nOriginal Traceback (most recent call last):\n  File \"/mnt/home/bhatta70/.local/lib/python3.6/site-packages/torch/nn/parallel/parallel_apply.py\", line 61, in _worker\n    output = module(*input, **kwargs)\n  File \"/mnt/home/bhatta70/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n    result = self.forward(*input, **kwargs)\n  File \"<ipython-input-26-96aa96028594>\", line 27, in forward\n    output = self.bert(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids, position_ids=position_ids, head_mask=head_mask, inputs_embeds=inputs_embeds)\n  File \"/mnt/home/bhatta70/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n    result = self.forward(*input, **kwargs)\n  File \"/opt/software/Python/3.6.4-foss-2018a/lib/python3.6/site-packages/transformers/models/bert/modeling_bert.py\", line 1006, in forward\n    return_dict=return_dict,\n  File \"/mnt/home/bhatta70/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n    result = self.forward(*input, **kwargs)\n  File \"/opt/software/Python/3.6.4-foss-2018a/lib/python3.6/site-packages/transformers/models/bert/modeling_bert.py\", line 592, in forward\n    output_attentions,\n  File \"/mnt/home/bhatta70/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n    result = self.forward(*input, **kwargs)\n  File \"/opt/software/Python/3.6.4-foss-2018a/lib/python3.6/site-packages/transformers/models/bert/modeling_bert.py\", line 477, in forward\n    past_key_value=self_attn_past_key_value,\n  File \"/mnt/home/bhatta70/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n    result = self.forward(*input, **kwargs)\n  File \"/opt/software/Python/3.6.4-foss-2018a/lib/python3.6/site-packages/transformers/models/bert/modeling_bert.py\", line 409, in forward\n    output_attentions,\n  File \"/mnt/home/bhatta70/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n    result = self.forward(*input, **kwargs)\n  File \"/opt/software/Python/3.6.4-foss-2018a/lib/python3.6/site-packages/transformers/models/bert/modeling_bert.py\", line 306, in forward\n    attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\nRuntimeError: CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 11.17 GiB total capacity; 10.52 GiB already allocated; 190.88 MiB free; 10.56 GiB reserved in total by PyTorch)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "trainer = Trainer(\n",
    "    model=model,                         \n",
    "    args=training_args,                  \n",
    "    train_dataset=tokenized_dataset,    \n",
    "    eval_dataset=tokenized_dataset,\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 26990\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class RegressionDataset(Dataset):\n",
    "    def __init__(self, input_ids, attention_mask, labels):\n",
    "        self.input_ids = input_ids\n",
    "        self.attention_mask = attention_mask\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {\n",
    "            'input_ids': torch.tensor(self.input_ids[idx]),\n",
    "            'attention_mask': torch.tensor(self.attention_mask[idx]),\n",
    "            'labels': torch.tensor(self.labels[idx])\n",
    "        }\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)  # Assuming all data entries have labels\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tokenized_dataset['input_ids']\n",
    "attention_mask = tokenized_dataset['attention_mask']\n",
    "labels = dataset['label']  # Assuming your labels are in the original dataset\n",
    "\n",
    "reg_dataset = RegressionDataset(input_ids, attention_mask, labels)\n",
    "dataloader = torch.utils.data.DataLoader(reg_dataset, batch_size=32, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.parameters at 0x2af9cff8f5c8>"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 3\n",
      "batch 82 complete. Loss:  1.1621150970458984\n",
      "batch 83 complete. Loss:  0.8956880569458008\n",
      "batch 84 complete. Loss:  0.8037869930267334\n",
      "batch 85 complete. Loss:  0.9169962406158447\n",
      "batch 86 complete. Loss:  0.8884814977645874\n",
      "batch 87 complete. Loss:  0.9881263971328735\n",
      "batch 88 complete. Loss:  0.9900961518287659\n",
      "batch 89 complete. Loss:  0.7278387546539307\n",
      "batch 90 complete. Loss:  0.8394187688827515\n",
      "batch 91 complete. Loss:  1.8925304412841797\n",
      "batch 92 complete. Loss:  1.0616230964660645\n",
      "batch 93 complete. Loss:  0.6486200094223022\n",
      "batch 94 complete. Loss:  0.6075191497802734\n",
      "batch 95 complete. Loss:  0.7383300065994263\n",
      "batch 96 complete. Loss:  1.0172334909439087\n",
      "batch 97 complete. Loss:  1.1043998003005981\n",
      "batch 98 complete. Loss:  1.0885484218597412\n",
      "batch 99 complete. Loss:  0.528542160987854\n",
      "batch 100 complete. Loss:  0.4628363847732544\n",
      "batch 101 complete. Loss:  0.7179670333862305\n",
      "batch 102 complete. Loss:  0.9117007255554199\n",
      "batch 103 complete. Loss:  0.5826869010925293\n",
      "batch 104 complete. Loss:  0.9647008180618286\n",
      "batch 105 complete. Loss:  0.8399885296821594\n",
      "batch 106 complete. Loss:  1.0078775882720947\n",
      "batch 107 complete. Loss:  1.768646478652954\n",
      "batch 108 complete. Loss:  0.7166151404380798\n",
      "batch 109 complete. Loss:  0.8663439750671387\n",
      "batch 110 complete. Loss:  0.8995974659919739\n",
      "batch 111 complete. Loss:  1.3047581911087036\n",
      "batch 112 complete. Loss:  0.8744204640388489\n",
      "batch 113 complete. Loss:  1.3521546125411987\n",
      "batch 114 complete. Loss:  0.9582007527351379\n",
      "batch 115 complete. Loss:  0.7794289588928223\n",
      "batch 116 complete. Loss:  1.8511930704116821\n",
      "batch 117 complete. Loss:  0.9558423757553101\n",
      "batch 118 complete. Loss:  1.020442008972168\n",
      "batch 119 complete. Loss:  1.261847734451294\n",
      "batch 120 complete. Loss:  1.9268523454666138\n",
      "batch 121 complete. Loss:  0.9821715950965881\n",
      "batch 122 complete. Loss:  1.033298373222351\n",
      "batch 123 complete. Loss:  1.3259050846099854\n",
      "batch 124 complete. Loss:  1.3578479290008545\n",
      "batch 125 complete. Loss:  1.027348518371582\n",
      "batch 126 complete. Loss:  0.8956184387207031\n",
      "batch 127 complete. Loss:  1.5023193359375\n",
      "batch 128 complete. Loss:  0.7026194334030151\n",
      "batch 129 complete. Loss:  1.1369038820266724\n",
      "batch 130 complete. Loss:  1.1097602844238281\n",
      "batch 131 complete. Loss:  0.8888040781021118\n",
      "batch 132 complete. Loss:  1.2141196727752686\n",
      "batch 133 complete. Loss:  1.9534186124801636\n",
      "batch 134 complete. Loss:  0.7472066283226013\n",
      "batch 135 complete. Loss:  1.1752047538757324\n",
      "batch 136 complete. Loss:  1.3033411502838135\n",
      "batch 137 complete. Loss:  1.7325860261917114\n",
      "batch 138 complete. Loss:  1.165770173072815\n",
      "batch 139 complete. Loss:  0.9664199948310852\n",
      "batch 140 complete. Loss:  1.1439918279647827\n",
      "batch 141 complete. Loss:  0.990615725517273\n",
      "batch 142 complete. Loss:  1.1017894744873047\n",
      "batch 143 complete. Loss:  1.899868130683899\n",
      "batch 144 complete. Loss:  1.0205011367797852\n",
      "batch 145 complete. Loss:  1.391206979751587\n",
      "batch 146 complete. Loss:  1.6471037864685059\n",
      "batch 147 complete. Loss:  0.9986029863357544\n",
      "batch 148 complete. Loss:  1.010965347290039\n",
      "batch 149 complete. Loss:  0.8971983194351196\n",
      "batch 150 complete. Loss:  0.8305156230926514\n",
      "batch 151 complete. Loss:  0.8325293064117432\n",
      "batch 152 complete. Loss:  1.1263686418533325\n",
      "batch 153 complete. Loss:  0.7103134393692017\n",
      "batch 154 complete. Loss:  1.2582411766052246\n",
      "batch 155 complete. Loss:  1.0385432243347168\n",
      "batch 156 complete. Loss:  0.7331576943397522\n",
      "batch 157 complete. Loss:  1.504512071609497\n",
      "batch 158 complete. Loss:  1.3052372932434082\n",
      "batch 159 complete. Loss:  1.3822511434555054\n",
      "batch 160 complete. Loss:  1.3828028440475464\n",
      "batch 161 complete. Loss:  1.1773266792297363\n",
      "batch 162 complete. Loss:  0.5254833102226257\n",
      "batch 163 complete. Loss:  0.9955195784568787\n",
      "batch 164 complete. Loss:  1.1465381383895874\n",
      "batch 165 complete. Loss:  1.6228344440460205\n",
      "batch 166 complete. Loss:  1.253300428390503\n",
      "batch 167 complete. Loss:  0.874374270439148\n",
      "batch 168 complete. Loss:  1.4438965320587158\n",
      "batch 169 complete. Loss:  0.8977532982826233\n",
      "batch 170 complete. Loss:  0.7697813510894775\n",
      "batch 171 complete. Loss:  0.8987386226654053\n",
      "batch 172 complete. Loss:  0.9110982418060303\n",
      "batch 173 complete. Loss:  1.6237455606460571\n",
      "batch 174 complete. Loss:  0.7583445310592651\n",
      "batch 175 complete. Loss:  0.9763049483299255\n",
      "batch 176 complete. Loss:  0.8497202396392822\n",
      "batch 177 complete. Loss:  0.7951887845993042\n",
      "batch 178 complete. Loss:  0.4244025945663452\n",
      "batch 179 complete. Loss:  1.2129311561584473\n",
      "batch 180 complete. Loss:  0.841458797454834\n",
      "batch 181 complete. Loss:  0.9701122045516968\n",
      "batch 182 complete. Loss:  0.7609667778015137\n",
      "batch 183 complete. Loss:  1.1731159687042236\n",
      "batch 184 complete. Loss:  0.9668098092079163\n",
      "batch 185 complete. Loss:  1.1306984424591064\n",
      "batch 186 complete. Loss:  1.1244962215423584\n",
      "batch 187 complete. Loss:  1.064247965812683\n",
      "batch 188 complete. Loss:  1.5256788730621338\n",
      "batch 189 complete. Loss:  1.040422797203064\n",
      "batch 190 complete. Loss:  1.1210956573486328\n",
      "batch 191 complete. Loss:  1.2649890184402466\n",
      "batch 192 complete. Loss:  1.324223518371582\n",
      "batch 193 complete. Loss:  0.7378864288330078\n",
      "batch 194 complete. Loss:  1.0222411155700684\n",
      "batch 195 complete. Loss:  0.7484849691390991\n",
      "batch 196 complete. Loss:  0.9981416463851929\n",
      "batch 197 complete. Loss:  0.5934350490570068\n",
      "batch 198 complete. Loss:  0.8362187147140503\n",
      "batch 199 complete. Loss:  0.7557234764099121\n",
      "batch 200 complete. Loss:  0.7184507250785828\n",
      "batch 201 complete. Loss:  1.4400392770767212\n",
      "batch 202 complete. Loss:  0.654399037361145\n",
      "batch 203 complete. Loss:  1.1719450950622559\n",
      "batch 204 complete. Loss:  0.9345911741256714\n",
      "batch 205 complete. Loss:  0.9715889692306519\n",
      "batch 206 complete. Loss:  1.6313170194625854\n",
      "batch 207 complete. Loss:  0.7183294296264648\n",
      "batch 208 complete. Loss:  0.5151238441467285\n",
      "batch 209 complete. Loss:  1.0838894844055176\n",
      "batch 210 complete. Loss:  0.7554353475570679\n",
      "batch 211 complete. Loss:  1.4524840116500854\n",
      "batch 212 complete. Loss:  0.9947032928466797\n",
      "batch 213 complete. Loss:  1.0095781087875366\n",
      "batch 214 complete. Loss:  1.0734033584594727\n",
      "batch 215 complete. Loss:  1.1732932329177856\n",
      "batch 216 complete. Loss:  1.195178747177124\n",
      "batch 217 complete. Loss:  0.9543599486351013\n",
      "batch 218 complete. Loss:  0.8085521459579468\n",
      "batch 219 complete. Loss:  1.3789856433868408\n",
      "batch 220 complete. Loss:  0.7292561531066895\n",
      "batch 221 complete. Loss:  1.043971061706543\n",
      "batch 222 complete. Loss:  0.9967116713523865\n",
      "batch 223 complete. Loss:  1.5168564319610596\n",
      "batch 224 complete. Loss:  0.6562609076499939\n",
      "batch 225 complete. Loss:  0.5908619165420532\n",
      "batch 226 complete. Loss:  0.7221129536628723\n",
      "batch 227 complete. Loss:  1.4269734621047974\n",
      "batch 228 complete. Loss:  0.9488435983657837\n",
      "batch 229 complete. Loss:  0.6904614567756653\n",
      "batch 230 complete. Loss:  1.0571213960647583\n",
      "batch 231 complete. Loss:  1.1337075233459473\n",
      "batch 232 complete. Loss:  0.9231710433959961\n",
      "batch 233 complete. Loss:  1.3880105018615723\n",
      "batch 234 complete. Loss:  2.25820255279541\n",
      "batch 235 complete. Loss:  1.2562345266342163\n",
      "batch 236 complete. Loss:  0.8291195631027222\n",
      "batch 237 complete. Loss:  1.5874886512756348\n",
      "batch 238 complete. Loss:  0.8869885206222534\n",
      "batch 239 complete. Loss:  0.794817328453064\n",
      "batch 240 complete. Loss:  0.6791328191757202\n",
      "batch 241 complete. Loss:  1.426369547843933\n",
      "batch 242 complete. Loss:  0.5804662108421326\n",
      "batch 243 complete. Loss:  0.5703200697898865\n",
      "batch 244 complete. Loss:  0.7929732799530029\n",
      "batch 245 complete. Loss:  1.1448054313659668\n",
      "batch 246 complete. Loss:  0.6246069073677063\n",
      "batch 247 complete. Loss:  1.3335559368133545\n",
      "batch 248 complete. Loss:  0.5006405115127563\n",
      "batch 249 complete. Loss:  0.9777593612670898\n",
      "batch 250 complete. Loss:  0.6144012808799744\n",
      "batch 251 complete. Loss:  0.7539221048355103\n",
      "batch 252 complete. Loss:  1.1298190355300903\n",
      "batch 253 complete. Loss:  0.9951416254043579\n",
      "batch 254 complete. Loss:  1.0956764221191406\n",
      "batch 255 complete. Loss:  0.6901835799217224\n",
      "batch 256 complete. Loss:  0.8899387717247009\n",
      "batch 257 complete. Loss:  0.5516558885574341\n",
      "batch 258 complete. Loss:  0.8370488882064819\n",
      "batch 259 complete. Loss:  1.2622367143630981\n",
      "batch 260 complete. Loss:  0.8508970141410828\n",
      "batch 261 complete. Loss:  0.8253924250602722\n",
      "batch 262 complete. Loss:  0.6569179892539978\n",
      "batch 263 complete. Loss:  1.1892937421798706\n",
      "batch 264 complete. Loss:  1.6091597080230713\n",
      "batch 265 complete. Loss:  1.1429200172424316\n",
      "batch 266 complete. Loss:  1.2960169315338135\n",
      "batch 267 complete. Loss:  0.931351900100708\n",
      "batch 268 complete. Loss:  1.1619341373443604\n",
      "batch 269 complete. Loss:  0.861579418182373\n",
      "batch 270 complete. Loss:  0.6021844744682312\n",
      "batch 271 complete. Loss:  0.8812830448150635\n",
      "batch 272 complete. Loss:  0.9156006574630737\n",
      "batch 273 complete. Loss:  1.271251916885376\n",
      "batch 274 complete. Loss:  0.9715064167976379\n",
      "batch 275 complete. Loss:  1.111218810081482\n",
      "batch 276 complete. Loss:  0.5551366209983826\n",
      "batch 277 complete. Loss:  1.2042795419692993\n",
      "batch 278 complete. Loss:  1.0258145332336426\n",
      "batch 279 complete. Loss:  0.7718862295150757\n",
      "batch 280 complete. Loss:  0.7616243362426758\n",
      "batch 281 complete. Loss:  0.9746524095535278\n",
      "batch 282 complete. Loss:  1.3008859157562256\n",
      "batch 283 complete. Loss:  0.8458279371261597\n",
      "batch 284 complete. Loss:  0.9886566996574402\n",
      "batch 285 complete. Loss:  0.7114665508270264\n",
      "batch 286 complete. Loss:  0.9861068725585938\n",
      "batch 287 complete. Loss:  0.9395139217376709\n",
      "batch 288 complete. Loss:  0.9887534379959106\n",
      "batch 289 complete. Loss:  1.7821966409683228\n",
      "batch 290 complete. Loss:  1.1793192625045776\n",
      "batch 291 complete. Loss:  1.1348212957382202\n",
      "batch 292 complete. Loss:  0.9995673298835754\n",
      "batch 293 complete. Loss:  1.3645470142364502\n",
      "batch 294 complete. Loss:  1.7671163082122803\n",
      "batch 295 complete. Loss:  1.2863714694976807\n",
      "batch 296 complete. Loss:  0.739037811756134\n",
      "batch 297 complete. Loss:  0.7640469074249268\n",
      "batch 298 complete. Loss:  1.1174020767211914\n",
      "batch 299 complete. Loss:  0.6196991205215454\n",
      "batch 300 complete. Loss:  0.8202781677246094\n",
      "batch 301 complete. Loss:  0.8285201787948608\n",
      "batch 302 complete. Loss:  1.2711784839630127\n",
      "batch 303 complete. Loss:  0.9225565791130066\n",
      "batch 304 complete. Loss:  0.6108821034431458\n",
      "batch 305 complete. Loss:  0.5163508057594299\n",
      "batch 306 complete. Loss:  0.9283626675605774\n",
      "batch 307 complete. Loss:  1.3191699981689453\n",
      "batch 308 complete. Loss:  0.8114455938339233\n",
      "batch 309 complete. Loss:  0.8052924871444702\n",
      "batch 310 complete. Loss:  0.7635224461555481\n",
      "batch 311 complete. Loss:  1.5912387371063232\n",
      "batch 312 complete. Loss:  1.0775364637374878\n",
      "batch 313 complete. Loss:  1.0186307430267334\n",
      "batch 314 complete. Loss:  1.0622532367706299\n",
      "batch 315 complete. Loss:  0.8148914575576782\n",
      "batch 316 complete. Loss:  0.5627514123916626\n",
      "batch 317 complete. Loss:  1.6918824911117554\n",
      "batch 318 complete. Loss:  1.2926278114318848\n",
      "batch 319 complete. Loss:  0.8370019793510437\n",
      "batch 320 complete. Loss:  0.9002712965011597\n",
      "batch 321 complete. Loss:  1.0642459392547607\n",
      "batch 322 complete. Loss:  1.2204837799072266\n",
      "batch 323 complete. Loss:  0.7693886756896973\n",
      "batch 324 complete. Loss:  0.749584436416626\n",
      "batch 325 complete. Loss:  0.6071231365203857\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-133-d0eb0edc6096>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Ensure outputs are single-dimensional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"batch {b} complete. Loss: \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mb\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    117\u001b[0m                    \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m                    \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight_decay'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m                    \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m                    )\n\u001b[1;32m    121\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/optim/functional.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loss_fn = nn.MSELoss()  # Mean Squared Error is common for regression\n",
    "optimizer = torch.optim.Adam([\n",
    "    {'params': model.module.bert.parameters(), 'lr': 1e-8}, \n",
    "    {'params': model.module.ft.parameters() , 'lr' : 1e-8}   # standard lr for our NN\n",
    "])\n",
    "num_epochs = 3\n",
    "\n",
    "\n",
    "# for epoch in range(num_epochs):\n",
    "#     print(epoch,\"/\",num_epochs)\n",
    "#     b=0\n",
    "#     for batch in dataloader:\n",
    "\n",
    "    \n",
    "    \n",
    "from torch.utils.data import random_split \n",
    "\n",
    "train_size = int(0.8 * len(reg_dataset))  # 80% of the dataset for training\n",
    "val_size = len(reg_dataset) - train_size \n",
    "\n",
    "# Create the train and validation datasets\n",
    "train_dataset, val_dataset = random_split(reg_dataset, [train_size, val_size])\n",
    "\n",
    "# Create DataLoaders\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=32, shuffle=False)  # No need to shuffle validation\n",
    "\n",
    "# Modify your training loop (add validation)\n",
    "for epoch in range(num_epochs):\n",
    "    print(epoch,\"/\",num_epochs)\n",
    "\n",
    "    ## Training Phase\n",
    "    model.train()  # Set model to training mode\n",
    "    for batch in train_dataloader:\n",
    "        input_ids = batch['input_ids'].to('cuda') \n",
    "        attention_mask = batch['attention_mask'].to('cuda')\n",
    "        labels = batch['labels'].to('cuda')\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        loss = loss_fn(outputs.squeeze(1), labels) # Ensure outputs are single-dimensional\n",
    "        loss.backward()\n",
    "        optimizer.step() \n",
    "        print(f\"batch {b} complete. Loss: \",loss.item())\n",
    "        b+=1\n",
    "    ## Validation Phase\n",
    "    model.eval()   # Set model to evaluation mode\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():  # Disable gradient calculation for validation\n",
    "        for batch in val_dataloader:\n",
    "            # ... (Similar to training, but no optimizer updates)\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            val_loss += loss_fn(outputs.squeeze(1), labels).item()\n",
    "\n",
    "    val_loss /= len(val_dataloader)\n",
    "    print(f\"Epoch {epoch} Validation Loss: {val_loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([93420.34047078])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inference\n",
    "text = \"The responsibilities of this position include collaboration with business stakeholders to identify business opportunities and requirements to develop associated AI/ML models that deliver useful, actionable recommendations, or which augment human capabilities in various work settings. The candidate is responsible for modeling complex business and engineering problems, discovering insights and deploying AI capabilities using machine learning and associated feature engineering techniques. Responsibilities also include tracking projects and driving work on them through to completion, as well as implementing technical best practices from the fields of machine learning and software engineering.\"\n",
    "inputs = tokenizer(text, return_tensors='pt').to('cuda')\n",
    "outputs = model(**inputs)\n",
    "scaler.inverse_transform(np.array([outputs.item()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
